{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrashDS\n",
    "\n",
    "#### Module 3 : Classification Tree\n",
    "\n",
    "Dataset from ISLR by *James et al.* : `Heart.csv`         \n",
    "Source: http://faculty.marshall.usc.edu/gareth-james/ISL/data.html     \n",
    "\n",
    "---\n",
    "\n",
    "### Essential Libraries\n",
    "\n",
    "Let us begin by importing the essential Python Libraries.    \n",
    "You may install any library using `conda install <library>`.    \n",
    "Most of the libraries come by default with the Anaconda platform.\n",
    "\n",
    "> NumPy : Library for Numeric Computations in Python  \n",
    "> Pandas : Library for Data Acquisition and Preparation  \n",
    "> Matplotlib : Low-level library for Data Visualization  \n",
    "> Seaborn : Higher-level library for Data Visualization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "sb.set() # set the default Seaborn style for graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need the essential Python libraries for (basic) Machine Learning.      \n",
    "Scikit-Learn (`sklearn`) will be our de-facto Machine Learning library in Python.   \n",
    "\n",
    "> `DecisionTreeClassifier` model from `sklearn.tree` : Our main model for Classification   \n",
    "> `plot_tree` method from `sklearn.tree` : Function to clearly visualize a Classification Tree   \n",
    "> `train_test_split` method from `sklearn.model_selection` : Random Train-Test splits     \n",
    "> `confusion_matrix` metric from `sklearn.metrics` : Primary performance metric for us "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Case Study : Personal Parameters vs Heart Disease\n",
    "\n",
    "\n",
    "### Import the Dataset\n",
    "\n",
    "The dataset is in CSV format; hence we use the `read_csv` function from Pandas.  \n",
    "Immediately after importing, take a quick look at the data using the `head` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file and check the format\n",
    "heartData = pd.read_csv('Heart.csv')\n",
    "heartData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the vital statistics of the dataset using the `type` and `shape` attributes.     \n",
    "Check the variables (and their types) in the dataset using the `info()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data type : \", type(heartData))\n",
    "print(\"Data dims : \", heartData.shape)\n",
    "heartData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the Dataset\n",
    "\n",
    "Drop the `Unnamed: 0` column as it contributes nothing to the problem.   \n",
    "Drop the rows where values are missing in any column using `dropna()`.    \n",
    "You may instead choose the `fillna()` method to fill in missing values. \n",
    "\n",
    "Convert the columns of type `object` to categorical data (factor) format.   \n",
    "Convert the non-obvious *categorical* columns to `category` format as well.    \n",
    "You may use `nunique()` method on each column to identify *categoricals*.   \n",
    "\n",
    "Check the format and vital statistics of the modified dataframe.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the first column (axis = 1) by its name\n",
    "heartData = heartData.drop('Unnamed: 0', axis = 1)\n",
    "\n",
    "# Drop the rows with `NA` values\n",
    "heartData = heartData.dropna()\n",
    "\n",
    "# Convert the Categoricals to appropriate type\n",
    "heartData[\"ChestPain\"] = heartData[\"ChestPain\"].astype('category')\n",
    "heartData[\"Thal\"] = heartData[\"Thal\"].astype('category')\n",
    "heartData[\"AHD\"] = heartData[\"AHD\"].astype('category')\n",
    "heartData[\"Sex\"] = heartData[\"Sex\"].astype('category')\n",
    "heartData[\"Fbs\"] = heartData[\"Fbs\"].astype('category')\n",
    "heartData[\"RestECG\"] = heartData[\"RestECG\"].astype('category')\n",
    "heartData[\"ExAng\"] = heartData[\"ExAng\"].astype('category')\n",
    "heartData[\"Ca\"] = heartData[\"Ca\"].astype('category')\n",
    "heartData[\"Slope\"] = heartData[\"Slope\"].astype('category')\n",
    "\n",
    "# Check the modified dataset\n",
    "heartData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Uni-Variate Classification : Predicting AHD using Chol\n",
    "\n",
    "We take `AHD` as our target variable for the Uni-Variate Classification.    \n",
    "We will start by setting up a Uni-Variate Classification Tree problem.   \n",
    "\n",
    "Response Variable : **AHD**     \n",
    "Predictor Feature : **Chol**    \n",
    "\n",
    "Check the mutual relationship between the variables to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of numeric variable against categorical variable\n",
    "f = plt.figure(figsize=(16, 4))\n",
    "sb.boxplot(x = \"Chol\", y = \"AHD\", data = heartData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Dataset\n",
    "\n",
    "Extract the Response and Predictor variables as two individual Pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(heartData[\"AHD\"])\n",
    "X = pd.DataFrame(heartData[[\"Chol\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset randomly into Train and Test datasets using `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Classification Model\n",
    "\n",
    "`DecisionTreeClassifier` is a class for the classification model in `sklearn`.     \n",
    "We need to create an object of the `DecisionTreeClassifier` class, as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a Decision Tree Classifier object\n",
    "dectree = DecisionTreeClassifier(max_depth = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Classification Tree model using the Train Set `X_train` and `y_train`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Linear Regression model\n",
    "dectree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have *trained* the model. Now it's time to visualize the Tree.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Classification Tree model\n",
    "f = plt.figure(figsize=(16, 8))\n",
    "plot_tree(dectree, \n",
    "          feature_names = X_train.columns,\n",
    "          class_names = [\"No\", \"Yes\"], \n",
    "          filled = True,\n",
    "          rounded = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goodness of Fit of the Model\n",
    "\n",
    "Check how good the predictions are on the Train Set.    \n",
    "Metrics : Classification Accuracy and Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Accuracy\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n",
    "\n",
    "# Confusion Matrix\n",
    "y_train_pred = dectree.predict(X_train)\n",
    "y_labels = ['No', 'Yes']\n",
    "\n",
    "ax = plt.subplot()\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred, y_labels), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = ax)\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('Actual labels')\n",
    "ax.xaxis.set_ticklabels(y_labels)\n",
    "ax.yaxis.set_ticklabels(y_labels)\n",
    "ax.set_ylim(len(y_labels), 0)  # temporary fix for heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how good the predictions are on the Test Set.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Accuracy\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n",
    "\n",
    "# Confusion Matrix\n",
    "y_test_pred = dectree.predict(X_test)\n",
    "y_labels = ['No', 'Yes']\n",
    "\n",
    "ax = plt.subplot()\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred, y_labels), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = ax)\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('Actual labels')\n",
    "ax.xaxis.set_ticklabels(y_labels)\n",
    "ax.yaxis.set_ticklabels(y_labels)\n",
    "ax.set_ylim(len(y_labels), 0)  # temporary fix for heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Classification Tree : Generic Function\n",
    "\n",
    "Let us write a generic function to model Classification Tree, as before.      \n",
    "Our Predictor variable(s) will be $X$ and the Response variable will be $Y$.   \n",
    "\n",
    "> Train data : (`X_Train`, `y_train`)    \n",
    "> Test data : (`X_test`, `y_test`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelDecisionTree(X_train, y_train, X_test, y_test, tree_depth):\n",
    "    '''\n",
    "        Function to perform Linear Regression with X_Train, y_train,\n",
    "        and test out the performance of the model on X_Test, y_test.\n",
    "    '''    \n",
    "    dectree = DecisionTreeClassifier(max_depth = tree_depth)  # create the decision tree object\n",
    "    dectree.fit(X_train, y_train)                             # train the decision tree model\n",
    "\n",
    "    # Predict Response corresponding to Predictors\n",
    "    y_train_pred = dectree.predict(X_train)\n",
    "    y_test_pred = dectree.predict(X_test)\n",
    "\n",
    "    # Visualize the Classification Tree model\n",
    "    f = plt.figure(figsize=(16, 8))\n",
    "    plot_tree(dectree, \n",
    "          feature_names = X_train.columns,\n",
    "          class_names = [\"No\", \"Yes\"], \n",
    "          filled = True,\n",
    "          rounded = True)\n",
    "    plt.show()\n",
    "\n",
    "    # Check the Goodness of Fit (on Train Data)\n",
    "    print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "    print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n",
    "    print()\n",
    "\n",
    "    # Check the Goodness of Fit (on Test Data)\n",
    "    print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "    print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n",
    "    print()\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    y_labels = ['No', 'Yes']\n",
    "    f, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    sb.heatmap(confusion_matrix(y_train, y_train_pred, y_labels),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "    sb.heatmap(confusion_matrix(y_test, y_test_pred, y_labels), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])\n",
    "                \n",
    "    axes[0].set_xlabel('Predicted labels')\n",
    "    axes[0].set_ylabel('Actual labels')\n",
    "    axes[0].xaxis.set_ticklabels(y_labels)\n",
    "    axes[0].yaxis.set_ticklabels(y_labels)\n",
    "    axes[1].set_xlabel('Predicted labels')\n",
    "    axes[1].set_ylabel('Actual labels')\n",
    "    axes[1].xaxis.set_ticklabels(y_labels)\n",
    "    axes[1].yaxis.set_ticklabels(y_labels)\n",
    "\n",
    "    axes[0].set_ylim(len(y_labels), 0)  # temporary fix for heatmap\n",
    "    axes[1].set_ylim(len(y_labels), 0)  # temporary fix for heatmap\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out the Generic Function to model Classification Tree on `AHD` against `RestBP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the Predictors and Response\n",
    "response = \"AHD\"\n",
    "predictors = [\"RestBP\"]\n",
    "\n",
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(heartData[response])\n",
    "X = pd.DataFrame(heartData[predictors])\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "# Model Classification Tree with Train-Test\n",
    "modelDecisionTree(X_train, y_train, X_test, y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out the Generic Function to model Classification Tree on `AHD` against `ChestPain`.     \n",
    "However, `ChestPain` is a categorical variable with labels as strings; not supported.    \n",
    "Hence, we will preprocess the variable to encode the labels to numerical data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the Categorical Predictor(s)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(heartData[\"ChestPain\"])\n",
    "heartData[\"encChestPain\"] = le.transform(heartData[\"ChestPain\"])\n",
    "\n",
    "# Specify the Predictors and Response\n",
    "response = \"AHD\"\n",
    "predictors = [\"encChestPain\"]\n",
    "\n",
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(heartData[response])\n",
    "X = pd.DataFrame(heartData[predictors])\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "# Model Classification Tree with Train-Test\n",
    "modelDecisionTree(X_train, y_train, X_test, y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Multi-Variate Classification Tree\n",
    "\n",
    "Let us set up a Multi-Variate Classification problem.   \n",
    "\n",
    "Response Variable : **AHD**     \n",
    "Predictor Feature : **Chol, RestBP, ChestPain, Thal**       \n",
    "\n",
    "Fortunately, our generic Classification Tree function works in this case as well.    \n",
    "However, we still need to encode categorical predictors before fitting the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the Categorical Predictor(s)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "leCP = LabelEncoder()\n",
    "leCP.fit(heartData[\"ChestPain\"])\n",
    "heartData[\"encChestPain\"] = leCP.transform(heartData[\"ChestPain\"])\n",
    "\n",
    "leTH = LabelEncoder()\n",
    "leTH.fit(heartData[\"Thal\"])\n",
    "heartData[\"encThal\"] = leTH.transform(heartData[\"Thal\"])\n",
    "\n",
    "\n",
    "# Specify the Predictors and Response\n",
    "response = \"AHD\"\n",
    "predictors = [\"Chol\", \"RestBP\", \"encChestPain\", \"encThal\"]\n",
    "\n",
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(heartData[response])\n",
    "X = pd.DataFrame(heartData[predictors])\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "# Model Classification Tree with Train-Test\n",
    "modelDecisionTree(X_train, y_train, X_test, y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Prediction using a Classification Tree Model\n",
    "\n",
    "Once we have trained a Classification Tree Model, we may use it to predict the Response.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the Categorical Predictor(s)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "leCP = LabelEncoder()\n",
    "leCP.fit(heartData[\"ChestPain\"])\n",
    "heartData[\"encChestPain\"] = leCP.transform(heartData[\"ChestPain\"])\n",
    "\n",
    "leTH = LabelEncoder()\n",
    "leTH.fit(heartData[\"Thal\"])\n",
    "heartData[\"encThal\"] = leTH.transform(heartData[\"Thal\"])\n",
    "\n",
    "\n",
    "# Specify the Predictors and Response\n",
    "response = \"AHD\"\n",
    "predictors = [\"Chol\", \"RestBP\", \"encChestPain\", \"encThal\"]\n",
    "\n",
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(heartData[response])\n",
    "X = pd.DataFrame(heartData[predictors])\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "# Model Classification Tree with Train-Test\n",
    "dectree = DecisionTreeClassifier(max_depth = 2)\n",
    "dectree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Response corresponding to Predictors\n",
    "y_train_pred = dectree.predict(X_train)\n",
    "y_test_pred = dectree.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's predict the value of Response for a few specific Data Points -- using the Classification Tree derived above.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract random Data Points for Prediction\n",
    "heartData_pred = heartData.sample(5)\n",
    "heartData_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Predictors for Prediction\n",
    "X_pred = pd.DataFrame(heartData_pred[predictors])\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_pred = dectree.predict(X_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Accuracy\n",
    "\n",
    "Let us check the errors in the Predicted values, compared to the Actuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the Actuals and Predictions\n",
    "y_pred = pd.DataFrame(y_pred, columns = [\"Predicted\"], index = heartData_pred.index)\n",
    "heartData_acc = pd.concat([heartData_pred[response], y_pred], axis = 1)\n",
    "\n",
    "y_correct = (heartData_acc[response] == heartData_acc[\"Predicted\"])\n",
    "y_correct = pd.DataFrame(list(y_correct), columns = [\"Correct\"], index = heartData_pred.index)\n",
    "heartData_acc = pd.concat([heartData_acc, y_correct], axis = 1)\n",
    "\n",
    "heartData_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Probability\n",
    "\n",
    "In case of any Classification Model, we should check the Class Probabilities along with the final Class Predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Predictors for Prediction\n",
    "X_pred = pd.DataFrame(heartData_pred[predictors])\n",
    "\n",
    "# Predict Response Probabilities corresponding to Predictors\n",
    "y_prob = dectree.predict_proba(X_pred)\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confidence of predicting any class essentially depends on the predicted probability and a threshold (default 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the Probabilities with the Predictions\n",
    "y_prob = pd.DataFrame(list(y_prob[:,1]), columns = [\"Confidence\"], index = heartData_pred.index)\n",
    "heartData_conf = pd.concat([heartData_acc, y_prob], axis = 1)\n",
    "\n",
    "heartData_conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE : You can always go back and try fitting a model with more predictors to check the difference.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
